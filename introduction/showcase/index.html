<!DOCTYPE html>
<html lang="en-US">
<head>
  <script src="https://docs.nosqlbench.io/theme.min.js" integrity="sha384-IpIaa84kOKgkF5EJ0fD/kBe2wtIIsIB60ANGmuJxeA0dz5bSRfwBwp2/QybtQpU2"></script>
  <link rel="stylesheet" href="https://docs.nosqlbench.io/abridge-switcher.css?h=4238d999f44a7bb130d5" />
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <link rel="preload" as="style" class="preStyle" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" crossorigin="anonymous" />
  <script defer src="https://docs.nosqlbench.io/search_index.en.js?h=ae47d253e455a3aaacb2" integrity="sha384-cP47owL9Iuak1e1AA21cJA4BgagQtaPwAXBQG7QgJeE2JKGgkCBROHbCj/Xym6KC"></script>
  <script defer src="https://docs.nosqlbench.io/abridge-bundle-nofacade.min.js?h=9bcf621a2fcab7336017" integrity="sha384-u8AROOUG6n2Xjk2+7pvkkfeSIqinjI1tmqeBpZRlZtc5KFO/8DyFfEir6fAE2wcq"></script>
  <meta name="base" content="https://docs.nosqlbench.io" />
<meta name="robots" content="index, follow" />
  <meta name="googlebot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1" />
  <meta name="bingbot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1" />
  <title>Showcase | NoSQLBench Project</title>
  <meta name="copyright" content="NoSQLBench Project" />
  <meta name="description" content="A description of what makes NoSQLBench Unique" />
  <link rel="canonical" href="https://docs.nosqlbench.io/introduction/showcase/" />
  <meta name="keywords" content="Abridge, Abridge.css, Zola, Theme, Zola Theme, getzola, Semantic Html, Fast, lightweight" />
  <meta property="og:url" content="https://docs.nosqlbench.io/introduction/showcase/" />
  <meta name="twitter:url" content="https://docs.nosqlbench.io/introduction/showcase/" />
  <meta property="og:description" content="A description of what makes NoSQLBench Unique" />
  <meta name="twitter:description" content="A description of what makes NoSQLBench Unique" />
  <meta property="og:title" content="Showcase | NoSQLBench Project" />
  <meta name="twitter:title" content="Showcase | NoSQLBench Project" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:image" content="https://docs.nosqlbench.io/nb5banner.png" />
  <meta property="og:image" content="https://docs.nosqlbench.io/nb5banner.png" />
  <meta property="og:site_name" content="NoSQLBench Project" />
  <meta property="og:locale" content="en_US" />
  <meta property="og:type" content="website" />
  <meta property="og:updated_time" content="" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="default" />
  <meta name="theme-color" content="#333333" />
  <meta name="msapplication-TileColor" content="#333333" />
  <link rel="manifest" href="https://docs.nosqlbench.io/site.webmanifest" />
  <link rel="mask-icon" href="https://docs.nosqlbench.io/safari-pinned-tab.svg" color="#ff9900" />
  <link rel="apple-touch-icon" sizes="180x180" href="https://docs.nosqlbench.io/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="https://docs.nosqlbench.io/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="https://docs.nosqlbench.io/favicon-16x16.png" />
  <noscript><link rel="stylesheet" href="https://docs.nosqlbench.io/nojs.css" /></noscript>
</head>
<body>
  <header>
    <nav>
      <div><h1><a href="https://docs.nosqlbench.io/"><img src="https://docs.nosqlbench.io/nb5logo.png" alt="NoSQLBench5" width="32" height="32" />NoSQLBench v5</a></h1></div><div>
        <ul><li> <h2><a href="https://docs.nosqlbench.io/getting-started/">Getting Started</a></h2> </li><li> <h2><a href="https://docs.nosqlbench.io/release-notes/">Release Notes</a></h2> </li><li class="js"><i type="reset" id="mode" class="svgs adjust"></i></li></ul>
      </div>
      <div>
        <form autocomplete=off class="js" name="goSearch" id="searchbox">
          <div class="searchd">
            <input id="searchinput" type="text" placeholder="Search" title="Search" />
            <button type="submit" title="Search"><i class="svgs search"></i></button>
          </div>
          <div><div id="suggestions"></div></div>
        </form>
      </div>

      <a href="http://github.com/nosqlbench/nosqlbench-build-docs" title="This doc site's project repo">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 22 18"
             fill="none"
             stroke="currentColor" stroke-width="1" stroke-linecap="round"
             stroke-linejoin="round">
          <path
              d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
        </svg>
      </a>
      <a href="http://nosqlbench.io" title="NoSQLBench Project Site">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 22 18"
             fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round"
             stroke-linejoin="round">
          <path
              d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
        </svg>
      </a>
    </nav>
    <hr /><div style="position:sticky"><span><a href="&#x2F;">NB5 Docsâ–º </a></span><span title="An introduction to what makes NoSQLBench Unique"><a href="&#x2F;introduction&#x2F;"><strong>Introductionâ–¼</strong> </a></span><span title="A description of what makes NoSQLBench Unique"><a href="&#x2F;introduction&#x2F;showcase&#x2F;"><strong>Showcase ðŸ–º</strong></a></span>
</div></header>
  <main><!-- active_page: introduction&#x2F;showcase.md -->
<!-- active_section: introduction&#x2F;_index.md -->


<!-- lower_root: _index.md -->
<!-- >upper_root: _index.md -->

<div class="toc" aria-hidden="true" id="">
<!--  <h4>Introduction</h4>--><div class="toc-sticky"><div class="toc-item"title="Release Notes for each major and some minor releases"><a href="&#x2F;release-notes&#x2F;">â–ºRelease Notes</a></div><div class="toc-item"title="An introduction to what makes NoSQLBench Unique"><strong>â–¼Introduction</strong></div><!-- subsection_page_path: &#x2F;introduction&#x2F;introduction&#x2F; -->
    <div class="toc-item-child">
      <a href="&#x2F;introduction&#x2F;introduction&#x2F;">NoSQLBench</a>
    </div><!-- subsection_page_path: &#x2F;introduction&#x2F;core-concepts&#x2F; -->
    <div class="toc-item-child">
      <a href="&#x2F;introduction&#x2F;core-concepts&#x2F;">Core Concepts</a>
    </div><!-- subsection_page_path: &#x2F;introduction&#x2F;showcase&#x2F; -->
    <div class="toc-item-child">
      <a href="&#x2F;introduction&#x2F;showcase&#x2F;"><strong>Showcase</strong></a>
    </div><!-- subsection_page_path: &#x2F;introduction&#x2F;community&#x2F; -->
    <div class="toc-item-child">
      <a href="&#x2F;introduction&#x2F;community&#x2F;">Community</a>
    </div><!-- subsection_page_path: &#x2F;introduction&#x2F;download&#x2F; -->
    <div class="toc-item-child">
      <a href="&#x2F;introduction&#x2F;download&#x2F;">Download</a>
    </div><!-- subsection_page_path: &#x2F;introduction&#x2F;principles&#x2F; -->
    <div class="toc-item-child">
      <a href="&#x2F;introduction&#x2F;principles&#x2F;">Design Principles</a>
    </div><div class="toc-item"title="Getting Started with NoSQLBench"><a href="&#x2F;getting-started&#x2F;">â–ºGetting Started</a></div><div class="toc-item"title="You can build workloads to simulate real-world data and access patterns."><a href="&#x2F;workloads-101&#x2F;">â–ºWorkloads 101</a></div><div class="toc-item"title="Detailed documentation on all options and features of NoSQLBench"><a href="&#x2F;user-guide&#x2F;">â–ºUser Guide</a></div><div class="toc-item"title="The NB5 Developer Guide"><a href="&#x2F;dev-guide&#x2F;">â–ºDev Guide</a></div><div class="toc-item"title="Detailed reference on drivers, formats, bindings, from auto-imported docs"><a href="&#x2F;reference&#x2F;">â–ºReference Section</a></div></div>
</div>

<article>

  <p>NoSQLBench has enjoyed a history of unique innovation, driven by the vision of its users and
builders, forged by the need for practical methods to test modern systems. This section covers a
sampling of what makes NoSQLBench unique. Many of these features simply could not be found in other
testing systems when they were needed. Thus, NoSQLBench took form as we solved them one after
another in the same tool space. The result is a powerful runtime and system of components and
concepts which can be adapted to a variety of testing needs.</p>
<h2 id="virtual-data-set">Virtual Data Set</h2>
<p>The <em>Virtual Dataset</em> capabilities within NoSQLBench allow you to generate data on the fly. There
are many reasons for using this technique in testing, but it is often a topic that is overlooked or
taken for granted.</p>
<p>This has multiple positive effects on the fidelity of a test:</p>
<ul>
<li>It is very much more efficient than interacting with storage systems and piping data around. Even
loading data from lightweight storage like NVMe will be more time intensive than simply generating
it in most cases.</li>
<li>As such, it leaves significant headroom on the table for introducing other valuable capabilities
into the test system, like advanced rate metering, coordinated omission awareness, etc.</li>
<li>Changing the data which is generated is as easy as changing the recipe.</li>
<li>The efficiency of the client is often high enough to support single-client test setups without
appreciable loss of capacity.</li>
<li>Because of modern procedural generation techniques, the variety and shape of data available is
significant. Increasing the space of possibilities is a matter of adding new algorithms. There is
no data bulk to manage.</li>
<li>Sophisticated test setups that are highly data dependent are portable. All you need is the test
client. The building blocks for data generation are included, and many pre-built testing scenarios
are already wired to use them.</li>
<li>It is straight-forward to design incremental data generation schemes which produce monotonic
identifiers, pseudo-random traversal over the values, or even statistically-shaped versions of
incremental or pseudo-random values.</li>
</ul>
<p>Additional details of this approach are explained below.</p>
<h5 id="industrial-strength">Industrial Strength</h5>
<p>The algorithms used to generate data are based on advanced techniques in the realm of variate
sampling. The authors have gone to great lengths to ensure that data generation is efficient and as
much O(1) in processing time as possible.</p>
<p>For example, one technique that is used to achieve this is to initialize and cache data in high
resolution look-up tables for distributions which may otherwise perform differently depending on
their respective density functions. The existing Apache Commons Math libraries have been adapted
into a set of interpolated Inverse Cumulative Distribution sampling functions. This means that you
can use them all in the same place as you would a Uniform distribution, and once initialized, they
sample with identical overhead. This means that by changing your test definition, you don't
accidentally change the behavior of your test client, only the data as intended.</p>
<h5 id="a-purpose-built-tool">A Purpose-Built Tool</h5>
<p>Many other testing systems avoid building a dataset generation component. It's a tough problem to
solve, so it's often just avoided. Instead, they use libraries like &quot;faker&quot; or other sources of data
which weren't designed for testing at scale. Faker is well named, no pun intended. It was meant as a
vignette and wire-framing library, not a source of test data for realistic results. If you are using
a testing tool for scale testing and relying on a faker variant, then you will almost certainly get
invalid results that do not represent how a system would perform in production.</p>
<p>The virtual dataset component of NoSQLBench is a library that was designed for high scale and
realistic data streams. It uses the limits of the data types in the JVM to simulate high cardinality
datasets which approximate production data distributions for realistic and reproducible results.</p>
<h5 id="deterministic">Deterministic</h5>
<p>The data that is generated by the virtual dataset libraries is deterministic. This means that for a
given cycle in a test, the operation that is synthesized for that cycle will be the same from one
session to the next. This is intentional. If you want to perturb the test data from one session to
the next, then you can most easily do it by simply selecting a different set of cycles as your
basis.</p>
<p>This means that if you find something interesting in a test run, you can go back to it just by
specifying the cycles in question. It also means that you aren't losing comparative value between
tests with additional randomness thrown in. The data you generate will still look random to the
human eye, but that doesn't mean that it can't be reproducible.</p>
<h5 id="statistically-shaped">Statistically Shaped</h5>
<p>If you want a normal distribution, you can have it simply by specifying <code>Normal(50,10)</code>. The values
drawn from this sampling function are deterministic <em>AND</em> normal. If you want another distribution,
you can have it. All the distributions provided by the Apache Commons math libraries are supported.
You can ask for a stream of floating point values 1 trillion values long, in any order. You can use
discrete or continuous distributions, with whatever distribution parameters you need.</p>
<h5 id="best-of-both-worlds">Best of Both Worlds</h5>
<p>Some might worry that fully synthetic testing data is not realistic enough. The devil is in the
details on these arguments, but suffice it to say that you can pick the level of real data you use
as seed data with NoSQLBench. You don't have to choose between realism and agility. The procedural
data generation approach allows you to have all the benefits of testing agility of low-entropy
testing tools while retaining nearly all the benefits of real testing data.</p>
<p>For example, using the alias sampling method and a published US census (public domain) list of names
and surnames tha occurred more than 100x, we can provide extremely accurate samples of names
according to the published labels and weights. The alias method allows us to sample accurately
in <em>O(1)</em> time from the entire dataset by turning a large number of weights into two uniform
samples. You will simply not find a better way to sample realistic (US) names than this. (If you do,
please file an issue!) Actually, any data set that you have in CSV form with a weight column can
also be used this way, so you're not strictly limited to US census data.</p>
<h5 id="java-idiomatic-extension">Java Idiomatic Extension</h5>
<p>The way that the virtual dataset component works allows Java developers to write any extension to
the data generation functions simply in the form of Java Functional interfaces. As long
as they include the annotation processor and annotate their classes, they will show up in the
runtime and be available to any workload by their class name.</p>
<p>Additionally, annotation based examples and annotation processing is used to hoist function docs
directly into the published docs that go along with any version of NoSQLBench.</p>
<h5 id="binding-recipes">Binding Recipes</h5>
<p>It is possible to stitch data generation functions together directly in a workload YAML. These are
data-flow sketches of functions that can be copied and pasted between workload descriptions to share
or remix data streams. This allows for the adventurous to build sophisticated virtual datasets that
emulate nuances of real datasets, but in a form that takes up less space on the screen than this
paragraph!</p>
<h2 id="portable-workloads">Portable Workloads</h2>
<p>All the workloads that you can build with NoSQLBench are self-contained in a workload file. This
is a statement-oriented configuration file that contains templates for the operations you want to
run in a workload.</p>
<p>This defines part of an activity - the iterative flywheel part that is run directly within an
activity type. This file contains everything needed to run a basic activity -- A set of statements
in some ratio. It can be used to start an activity, or as part of several activities within a
scenario.</p>
<h3 id="standard-yaml-format">Standard YAML Format</h3>
<p>The format for describing statements in NoSQLBench is generic, but in a particular way that is
specialized around describing statements for a workload. That means that you can use the same YAML
format to describe a workload for kafka as you can for Apache Cassandra or DSE.</p>
<p>The YAML structure has been tailored to describing statements, their data generation bindings, how
they are grouped and selected, and the parameters needed by drivers, like whether they should be
prepared statements or not.</p>
<p>Further, the YAML format allows for defaults and overrides with a very simple mechanism that reduces
editing fatigue for frequent users.</p>
<p>You can also templatize document-wide macro parameters which are taken from the command line just
like any other parameter. This is a way of templating a workload and make it multi-purpose or
adjustable on the fly.</p>
<h3 id="experimentation-friendly">Experimentation Friendly</h3>
<p>Because the workload YAML format is generic across driver types, it is possible to ask one driver
type to interpret the statements that are meant for another. This isn't generally a good idea, but
it becomes extremely handy when you want to have a high level driver type like <code>stdout</code>
interpret the syntax of another driver like <code>cql</code>. When you do this, the stdout activity type _
plays_ the statements to your console as they would be executed in CQL, data bindings and all.</p>
<p>This means you can empirically and directly demonstrate and verify access patterns, data skew, and
other dataset details before you change back to cql mode and turn up the settings for a higher scale
test. It takes away the guess work about what your test is actually doing, and it works for all
drivers.</p>
<h2 id="scripting-environment">Scripting Environment</h2>
<p>The ability to write open-ended testing simulations is provided in NoSQLBench by means of a scripted
runtime, where each scenario is driven from a control script that can do anything the user wants.</p>
<h5 id="dynamic-parameters">Dynamic Parameters</h5>
<p>Some configuration parameters of activities are designed to be assignable while a workload is
running. This makes things like threads, rates, and other workload dynamics in real-time. The
internal APIs work with the scripting environment to expose these parameters directly to scenario
scripts. Drivers that are provided to NoSQLBench can also expose dynamic parameters in the same way
so that anything can be scripted dynamically when needed.</p>
<h5 id="scripting-automatons">Scripting Automatons</h5>
<p>When a NoSQLBench scenario is running, it is under the control of a single-threaded script. Each
activity that is started by this script is run within its own thread pool, simultaneously and
asynchronously.</p>
<p>The control script has executive control of the activities, as well as full visibility into the
metrics that are provided by each activity. The way these two parts of the runtime meet is through
the service objects which are installed into the scripting runtime. These service objects provide a
named access point for each running activity and its metrics.</p>
<p>This means that the scenario script can do something simple, like start activities and wait for them
to complete, OR, it can do something more sophisticated like dynamically and iteratively scrutinize
the metrics and make real-time adjustments to the workload while it runs.</p>
<h5 id="analysis-methods">Analysis Methods</h5>
<p>Scripting automatons that do feedback-oriented analysis of a target system are called analysis
methods in NoSQLBench. These are used for advanced testing scenarios. Advanced testers or 
researchers can build their own in a way that interacts with a live system with feedback and 
sampling times measured in seconds.</p>
<h5 id="command-line-scripting">Command Line Scripting</h5>
<p>The command line has the form of basic test commands and parameters. These command get converted
directly into scenario control script in the order they appear. The user can choose whether to stay
in high level executive mode, with simple commands like <code>nb5 test-scenario ...</code>, or to drop
directly into script design. They can look at the equivalent script for any command line by running
<code>--show-script</code>. If you take the script that is dumped to console and run it, it will do exactly the
same thing as if you hadn't even looked at it and just ran basic commands on the command line.</p>
<p>There are even ways to combine script fragments, full commands, and calls to scripts on the command
line. Since each variant is merely a way of constructing scenario script, they all get composited
together before the scenario script is run.</p>
<p>New introductions to NoSQLBench should focus on the command line. Once a user is familiar with this,
it is up to them whether to tap into the deeper functionality. If they don't need to know about
scenario scripting, then they shouldn't have to learn about it to be effective. This is what we are
calling a <em>scalable user experience</em>.</p>
<h5 id="compared-to-dsls">Compared to DSLs</h5>
<p>Other tools may claim that their DSL makes scenario &quot;simulation&quot; easier. In practice, any DSL is
generally dependent on a development tool to lay the language out in front of a user in a fluent
way. This means that DSLs are almost always developer-targeted tools, and mostly useless for casual
users who don't want to break out an IDE.</p>
<p>One of the things a DSL proponent may tell you is that it tells you &quot;all the things you can do!&quot;.
This is de-facto the same thing as it telling you
&quot;all the things you can't do&quot; because it's not part of the DSL. This is not a win-win for the user.
For DSL-based systems, the user is required to use the DSL, even when it interferes with the 
user's creative control. Most DSLs aren't rich enough to do much that is interesting from a 
simulation perspective.</p>
<p>In NoSQLBench, we don't force the user to use the programming abstractions except at a very surface
level -- the CLI. It is up to the user whether to open the secret access panel for the more
advanced functionality. If they decide to do this, we give them a commodity language (ECMAScript),
and we wire it into all the things they were already using. We don't take away their creative
freedom by telling them what they can't do. This way, users can pick their level of investment and
reward as best fits their individual needs, as it should be.</p>
<h5 id="scripting-extensions">Scripting Extensions</h5>
<p>Also mentioned under the section on modularity, it is relatively easy for a developer to add their
own scripting extensions into NoSQLBench as named service objects.</p>
<h2 id="modular-architecture">Modular Architecture</h2>
<p>The internal architecture of NoSQLBench is modular throughout. Everything from the scripting
extensions to data generation is enumerated at compile time into a service descriptor, and then
discovered at runtime by the SPI mechanism in Java.</p>
<p>This means that extending and customizing bundles and features is quite manageable.</p>
<p>It also means that it is relatively easy to provide a suitable API for multi-protocol support. In
fact, there are several drivers available in the current NoSQLBench distribution. You can list them
out with <code>nb5 --list-drivers</code>, and you can get help on how to use each of them
with <code>nb5 help &lt;driver name&gt;</code>.</p>
<p>This also is a way for us to encourage and empower other contributors to help develop the
capabilities and reach of NoSQLBench. By encouraging others to help us build NoSQLBench modules and
extensions, we can help more users in the NoSQL community at large.</p>
<h2 id="high-fidelity-metrics">High Fidelity Metrics</h2>
<p>Since NoSQLBench has been built as a serious testing tool for all users, some attention was
necessary on the way metric are used. More details follow...</p>
<h5 id="discrete-reservoirs">Discrete Reservoirs</h5>
<p>In NoSQLBench, we avoid the use of time-decaying metrics reservoirs. Internally, we use HDR
reservoirs with discrete time boundaries. This is so that you can look at the min and max values and
know that they apply accurately to the whole sampling window.</p>
<h5 id="metric-naming">Metric Naming</h5>
<p>All running activities have a symbolic alias that identifies them for the purposes of automation and
metrics. If you have multiple activities running concurrently, they will have different names and
will be represented distinctly in the metrics flow.</p>
<h5 id="precision-and-units">Precision and Units</h5>
<p>By default, the internal HDR histogram reservoirs are kept at 4 digits of precision. All timers are
kept at nanosecond resolution.</p>
<h5 id="metrics-reporting">Metrics Reporting</h5>
<p>Metrics can be reported via graphite as well as CSV, logs, HDR logs, and HDR stats summary CSV
files.</p>
<h5 id="coordinated-omission">Coordinated Omission</h5>
<p>The metrics naming and semantics in NoSQLBench are set up so that you can have coordinated omission
metrics when they are appropriate, but there are no there changes when they are not. This means that
the metric names and meanings remain stable in any case.</p>
<p>Particularly, NoSQLBench tries to avoid the term &quot;latency&quot; altogether as it is often overused and 
thus prone to confusing people.</p>
<p>Instead, the terms <code>service time</code>, <code>wait time</code>, and <code>response time</code> are used. These are abbreviated
in metrics as <code>servicetime</code>, <code>waittime</code>, and
<code>responsetime</code>.</p>
<p>The <code>servicetime</code> metric is the only one which is always present. When a rate limiter is used, then
additionally <code>waittime</code> and <code>responsetime</code> are reported.</p>
<h2 id="advanced-testing-features">Advanced Testing Features</h2>
<p>ðŸ‘‰ Some features discussed here are only for advanced testing scenarios. First-time users should
become familiar with the basic options first.</p>
<h5 id="hybrid-rate-limiting">Hybrid Rate Limiting</h5>
<p>Rate limiting is a complicated endeavor, if you want to do it well. The basic rub is that going fast
means you have to be less accurate, and vice-versa. As such, rate limiting is a parasitic drain on
any system. The act of rate limiting itself poses a limit to the maximum rate, regardless of the
settings you pick. This occurs as a side-effect of forcing your system to interact with some
hardware notion of time passing, which takes CPU cycles that could be going to the thing you are
limiting.</p>
<p>This means that in practice, rate limiters are often very featureless. It's daunting enough to need
rate limiting, and asking for anything more than that is often wishful thinking. Not so in
NoSQLBench.</p>
<p>The rate limiter in NoSQLBench provides a comparable degree of performance and accuracy to others
found in the Java ecosystem, but it <em>also</em> has advanced features:</p>
<ul>
<li>It allows a sliding scale between average rate limiting and strict rate limiting, called _
bursting_.</li>
<li>It internally accumulates delay time, for C.O. friendly metrics which are separately tracked for
each and every operation.</li>
<li>It is resettable and reconfigurable on the fly, including the bursting rate.</li>
<li>It provides its configured values in addition to performance data in metrics, capturing your rate
limiter settings as a simple matter of metrics collection.</li>
<li>It comes with advanced scripting helpers which allow you to read data directly from histogram
reservoirs, or control the reservoir window programmatically.</li>
</ul>
<h5 id="flexible-error-handling">Flexible Error Handling</h5>
<p>An emergent facility in NoSQLBench is the way that error are handled within an activity. For
example, with the CQL activity type, you are able to route error handling for any of the known
exception types. You can count errors, you can log them. You can cause errored operations to
auto-retry if possible, up to a configurable number of tries.</p>
<p>This means, that as a user, you get to decide what your test is about. Is it about measuring some
nominal but anticipated level of errors due to intentional over-saturation? If so, then count the
errors, and look at their histogram data for timing details within the available timeout.</p>
<p>Are you doing a basic stability test, where you want the test to error out for even the slightest
error? You can configure for that if you need.</p>
<h5 id="cycle-logging">Cycle Logging</h5>
<p>It is possible to record the result status of each and every cycle in a NoSQLBench test run. If the
results are mostly homogeneous, the RLE encoding of the results will reduce the output file down to
a small fraction of the number of cycles. The errors are mapped to ordinals by error type, and these
ordinals are stored into a direct RLE-encoded log file. For most testing where most of the results
are simply success, this file will be tiny. You can also convert the cycle log into textual form for
other testing and post-processing and vice-versa.</p>
<h5 id="op-sequencing">Op Sequencing</h5>
<p>The way that operations are planned for execution in NoSQLBench is based on a stable ordering that
is configurable. The statement forms are mixed together based on their relative ratios. The three
schemes currently supported are round-robin with exhaustion (bucket), duplicate in order
(concat), and a way to spread each statement out over the unit interval
(interval). These account for most configuration scenarios without users having to micromanage
their statement templates.</p>

<p><b><a href="#">Back to top</a></b></p>
</article>
<div class="toc" aria-hidden="true">
  <div class="toc-sticky">
    <h5>Showcase</h5>
    <div class="toc-item">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#virtual-data-set">Virtual Data Set</a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#industrial-strength"><small>- Industrial Strength</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#a-purpose-built-tool"><small>- A Purpose-Built Tool</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#deterministic"><small>- Deterministic</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#statistically-shaped"><small>- Statistically Shaped</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#best-of-both-worlds"><small>- Best of Both Worlds</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#java-idiomatic-extension"><small>- Java Idiomatic Extension</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#binding-recipes"><small>- Binding Recipes</small></a>
    </div>
    <div class="toc-item">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#portable-workloads">Portable Workloads</a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#standard-yaml-format"><small>- Standard YAML Format</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#experimentation-friendly"><small>- Experimentation Friendly</small></a>
    </div>
    <div class="toc-item">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#scripting-environment">Scripting Environment</a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#dynamic-parameters"><small>- Dynamic Parameters</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#scripting-automatons"><small>- Scripting Automatons</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#analysis-methods"><small>- Analysis Methods</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#command-line-scripting"><small>- Command Line Scripting</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#compared-to-dsls"><small>- Compared to DSLs</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#scripting-extensions"><small>- Scripting Extensions</small></a>
    </div>
    <div class="toc-item">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#modular-architecture">Modular Architecture</a>
    </div>
    <div class="toc-item">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#high-fidelity-metrics">High Fidelity Metrics</a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#discrete-reservoirs"><small>- Discrete Reservoirs</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#metric-naming"><small>- Metric Naming</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#precision-and-units"><small>- Precision and Units</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#metrics-reporting"><small>- Metrics Reporting</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#coordinated-omission"><small>- Coordinated Omission</small></a>
    </div>
    <div class="toc-item">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#advanced-testing-features">Advanced Testing Features</a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#hybrid-rate-limiting"><small>- Hybrid Rate Limiting</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#flexible-error-handling"><small>- Flexible Error Handling</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#cycle-logging"><small>- Cycle Logging</small></a>
    </div>
    <div class="toc-item-child">
      <a class="subtext" href="https://docs.nosqlbench.io/introduction/showcase/#op-sequencing"><small>- Op Sequencing</small></a>
    </div>
  </div>
</div>
  </main>
  <footer>
    <hr />
    <div class="c">
      <nav>
        <ul></ul>
      </nav>
      <p class="s90">Copyright &copy; 2023-2023 NoSQLBench Project</p>
    </div>
  </footer>
</body>
</html>
